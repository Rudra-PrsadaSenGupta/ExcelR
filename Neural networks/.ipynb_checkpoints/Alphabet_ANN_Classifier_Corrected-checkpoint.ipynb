{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c1b3586",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks (ANN) for Alphabet Classification\n",
    "In this notebook, we will develop a classification model using Artificial Neural Networks (ANN) to classify the alphabet data into predefined categories. We will also tune the hyperparameters to improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55425af",
   "metadata": {},
   "source": [
    "## Step 1: Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16b46967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0      T     2     8      3       5      1     8    13      0      6      6   \n",
       "1      I     5    12      3       7      2    10     5      5      4     13   \n",
       "2      D     4    11      6       8      6    10     6      2      6     10   \n",
       "3      N     7    11      6       6      3     5     9      4      6      4   \n",
       "4      G     2     1      3       1      1     8     6      6      6      6   \n",
       "\n",
       "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0      10       8      0       8      0       8  \n",
       "1       3       9      2       8      4      10  \n",
       "2       3       7      3       7      3       9  \n",
       "3       4      10      6      10      2       8  \n",
       "4       5       9      1       7      5      10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "alphabets_data = pd.read_csv('Alphabets_data.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "alphabets_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43031e6f",
   "metadata": {},
   "source": [
    "### Summary of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1aea935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 20000\n",
      "Number of features: 17\n",
      "Class distribution:\n",
      "U    813\n",
      "D    805\n",
      "P    803\n",
      "T    796\n",
      "M    792\n",
      "A    789\n",
      "X    787\n",
      "Y    786\n",
      "N    783\n",
      "Q    783\n",
      "F    775\n",
      "G    773\n",
      "E    768\n",
      "B    766\n",
      "V    764\n",
      "L    761\n",
      "R    758\n",
      "I    755\n",
      "O    753\n",
      "W    752\n",
      "S    748\n",
      "J    747\n",
      "K    739\n",
      "C    736\n",
      "H    734\n",
      "Z    734\n",
      "Name: letter, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Summarize key statistics about the data\n",
    "print(\"Number of samples:\", alphabets_data.shape[0])\n",
    "print(\"Number of features:\", alphabets_data.shape[1])\n",
    "print(\"Class distribution:\")\n",
    "print(alphabets_data['letter'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc607d2d",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "- Handle missing values (if any)\n",
    "- Normalize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "318b6b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter    0\n",
      "xbox      0\n",
      "ybox      0\n",
      "width     0\n",
      "height    0\n",
      "onpix     0\n",
      "xbar      0\n",
      "ybar      0\n",
      "x2bar     0\n",
      "y2bar     0\n",
      "xybar     0\n",
      "x2ybar    0\n",
      "xy2bar    0\n",
      "xedge     0\n",
      "xedgey    0\n",
      "yedge     0\n",
      "yedgex    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(alphabets_data.isnull().sum())\n",
    "\n",
    "# Normalize the feature columns\n",
    "X = alphabets_data.drop(columns=['letter'])\n",
    "y = alphabets_data['letter']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e4b39",
   "metadata": {},
   "source": [
    "## Step 2: ANN Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d07d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for ANN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Build a basic ANN model\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(26, activation='softmax')  # Multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83736099",
   "metadata": {},
   "source": [
    "## Step 3: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c883137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Generate a classification report\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d664546a",
   "metadata": {},
   "source": [
    "## Step 4: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c6043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the number of hidden layers, neurons, and activation functions\n",
    "# Hyperparameter Tuning Example with Random Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model(activation='relu', optimizer='adam'):\n",
    "    model = Sequential([\n",
    "        Dense(64, input_shape=(X_train.shape[1],), activation=activation),\n",
    "        Dense(32, activation=activation),\n",
    "        Dense(26, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=10, verbose=0)\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'batch_size': [10, 20],\n",
    "    'epochs': [10, 20]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and performance\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2c737",
   "metadata": {},
   "source": [
    "## Step 5: Visualization of Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy over epochs\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss over epochs\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
