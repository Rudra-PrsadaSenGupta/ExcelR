{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b2a064",
   "metadata": {},
   "source": [
    "# Association Rule Mining and Apriori Algorithm with Detailed Explanation\n",
    "This notebook demonstrates how to apply association rule mining using the Apriori algorithm on the Online Retail dataset. The goal is to discover relationships between products purchased together and provide detailed explanations along the way.\n",
    "\n",
    "### Objectives:\n",
    "- Preprocess the dataset\n",
    "- Apply the Apriori algorithm\n",
    "- Extract meaningful association rules\n",
    "- Visualize and interpret the results\n",
    "- Answer common interview questions related to association rule mining\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8e21d1",
   "metadata": {},
   "source": [
    "## Task 1: Data Preprocessing\n",
    "Before applying the Apriori algorithm, we need to clean the dataset by removing missing values, duplicates, and converting the data into the appropriate format for rule mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239cfcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrimp,almonds,avocado,vegetables mix,green gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>burgers,meatballs,eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chutney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkey,avocado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mineral water,milk,energy bar,whole wheat rice...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words\n",
       "0  shrimp,almonds,avocado,vegetables mix,green gr...\n",
       "1                             burgers,meatballs,eggs\n",
       "2                                            chutney\n",
       "3                                     turkey,avocado\n",
       "4  mineral water,milk,energy bar,whole wheat rice..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Online retail.csv'\n",
    "data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Drop missing values and duplicates\n",
    "data.dropna(inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78f1954",
   "metadata": {},
   "source": [
    "## Task 2: Exploratory Data Analysis (EDA)\n",
    "We'll explore the dataset by visualizing key trends, such as product quantities and total revenue per country. This will help us understand the general structure of the data before we apply association rule mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f24120",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Quantity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Quantity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Visualize the distribution of product quantities purchased\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantity\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution of Product Quantities Purchased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantity\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Quantity'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize the distribution of product quantities purchased\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Quantity'], bins=50, kde=True)\n",
    "plt.title('Distribution of Product Quantities Purchased')\n",
    "plt.xlabel('Quantity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Visualize total revenue by country\n",
    "data['Revenue'] = data['Quantity'] * data['UnitPrice']\n",
    "country_revenue = data.groupby('Country')['Revenue'].sum().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=country_revenue.values, y=country_revenue.index)\n",
    "plt.title('Total Revenue by Country')\n",
    "plt.xlabel('Revenue')\n",
    "plt.ylabel('Country')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdcc684",
   "metadata": {},
   "source": [
    "## Task 3: Association Rule Mining with Apriori Algorithm\n",
    "We will now apply the Apriori algorithm to find frequent itemsets and generate association rules. We'll use the `mlxtend` library to implement the Apriori algorithm and extract rules based on thresholds for support, confidence, and lift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8fae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare data for association rule mining\n",
    "# Pivot the dataset so that each product in each invoice is represented as 1 (if purchased)\n",
    "basket = (data.groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))\n",
    "\n",
    "# Convert quantities to binary values (1 if purchased, 0 otherwise)\n",
    "def encode_units(x):\n",
    "    return 1 if x >= 1 else 0\n",
    "\n",
    "basket_sets = basket.applymap(encode_units)\n",
    "\n",
    "# Apply the Apriori algorithm to find frequent itemsets\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Set a minimum support threshold (e.g., 0.01 for 1%)\n",
    "frequent_itemsets = apriori(basket_sets, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Generate association rules with a minimum confidence threshold of 0.2\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.2)\n",
    "\n",
    "# Sort the rules by lift and display the top 10\n",
    "rules = rules.sort_values('lift', ascending=False)\n",
    "rules.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd876575",
   "metadata": {},
   "source": [
    "## Task 4: Visualization of Association Rules\n",
    "We will visualize the top association rules based on their lift value to understand the strongest product associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254da5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the top 10 association rules based on lift\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=rules['lift'].head(10), y=rules['consequents'].head(10).astype(str))\n",
    "plt.title('Top 10 Association Rules by Lift')\n",
    "plt.xlabel('Lift')\n",
    "plt.ylabel('Consequent Items')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e249065b",
   "metadata": {},
   "source": [
    "## Task 5: Interview Questions and Answers\n",
    "Here are some common interview questions related to the Apriori algorithm and association rule mining, with detailed answers.\n",
    "\n",
    "**1. What is Lift and why is it important in Association Rules?**\n",
    "**Answer**: Lift is a measure of how much more likely two items are to be purchased together compared to if they were independent. A lift greater than 1 indicates a strong association, meaning that the occurrence of the antecedent increases the likelihood of the consequent occurring. Lift helps in identifying the strength of the relationship between items.\n",
    "\n",
    "**2. What is Support and Confidence? How do you calculate them?**\n",
    "**Answer**: Support is the proportion of transactions that contain a particular itemset. It indicates how frequently an item or set of items appears in the dataset. Confidence is a measure of the likelihood that the consequent will occur given that the antecedent has occurred. Both metrics help in determining which rules are meaningful.\n",
    "\n",
    "- **Support**: Support(X) = (Transactions containing X) / (Total Transactions)\n",
    "- **Confidence**: Confidence(X -> Y) = Support(X and Y) / Support(X)\n",
    "\n",
    "**3. What are some limitations or challenges of Association Rules mining?**\n",
    "**Answer**: Some challenges include:\n",
    "- Handling large datasets: Frequent itemset generation can be computationally expensive.\n",
    "- Selecting appropriate thresholds: It can be difficult to set meaningful thresholds for support, confidence, and lift.\n",
    "- Overfitting: Too many rules can lead to overfitting, generating rules that are not practically useful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c02ed4c",
   "metadata": {},
   "source": [
    "## Task 6: Conclusion\n",
    "In this notebook, we applied the Apriori algorithm to discover associations between products purchased together in the Online Retail dataset. The top rules based on lift revealed important product associations, which could be used for targeted marketing or cross-selling strategies.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Support**: Frequency of occurrence of an itemset in transactions.\n",
    "- **Confidence**: Likelihood of the consequent occurring given that the antecedent occurs.\n",
    "- **Lift**: Measure of how much more likely the antecedent and consequent are to occur together compared to if they were independent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
